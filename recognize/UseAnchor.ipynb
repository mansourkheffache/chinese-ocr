{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: top3: [(3541, '99.70'), (452, '0.30'), (3094, '0.00')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-25 15:38:44.250524: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "!python anchor/model_test.py anchor/data/test/é”—/C004-f-f.png\n",
    "#import anchor.model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(888)\n",
    "np.random.seed(888)\n",
    "tf.set_random_seed(888)\n",
    "\n",
    "IMG_SIZE = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "    Test file or on a subset of 2013 CASIA competition data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "import random\n",
    "import copy\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend\n",
    "from the_model import model_8\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-p\", \"--pred\", action=\"store_true\")\n",
    "parser.add_argument(\"infile\", nargs=\"?\", type=argparse.FileType('rb'))\n",
    "args = parser.parse_args()\n",
    "\n",
    "random.seed(888)\n",
    "np.random.seed(888)\n",
    "tf.set_random_seed(888)\n",
    "\n",
    "IMG_SIZE = 96\n",
    "\n",
    "Pred_Details = False\n",
    "if args.pred or args.infile:\n",
    "    Pred_Details = True\n",
    "\n",
    "TEST_PATH = os.path.join(\"anchor\",\"data\", \"test\")\n",
    "WEIGHTS_PATH = os.path.join(\"anchor\",\"data\", \"weights08.h5\")\n",
    "LABELS_PATH = os.path.join(\"anchor\",\"data\", \"labels.txt\")\n",
    "\n",
    "label_file = codecs.open(LABELS_PATH, \"r\", \"utf-8\")\n",
    "klasses = [a.strip() for a in label_file.readlines()]\n",
    "# print(len(klasses))\n",
    "label_file.close()\n",
    "\n",
    "model = model_8(IMG_SIZE, len(klasses))\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if args.infile:\n",
    "    test_data = np.ndarray([1, IMG_SIZE, IMG_SIZE], dtype=np.uint8)\n",
    "    test_data[0] = imread(args.infile)\n",
    "\n",
    "else:\n",
    "    label_pngs = []\n",
    "    for k, v in enumerate(klasses):\n",
    "        for png in os.listdir(os.path.join(TEST_PATH, v)):\n",
    "            label_pngs.append((k, v, png))\n",
    "\n",
    "    print(\"Total number of test samples:\", len(label_pngs))\n",
    "    test_data = np.ndarray([len(label_pngs), IMG_SIZE, IMG_SIZE],\n",
    "                           dtype=np.uint8)\n",
    "    test_label = np.ndarray([len(label_pngs)], dtype=np.uint32)\n",
    "\n",
    "    i = 0\n",
    "    for label_png in label_pngs:\n",
    "        fimg = open(os.path.join(TEST_PATH, label_png[1], label_png[2]), 'rb')\n",
    "        test_data[i] = imread(fimg)\n",
    "        test_label[i] = label_png[0]\n",
    "        fimg.close()\n",
    "        i += 1\n",
    "\n",
    "    y_test = to_categorical(test_label)\n",
    "\n",
    "x_test = test_data.reshape(test_data.shape[0],\n",
    "                           test_data.shape[1],\n",
    "                           test_data.shape[2],\n",
    "                           1)\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_test /= 255.0\n",
    "\n",
    "\n",
    "def top_predictions(n, pred):\n",
    "    tops = []\n",
    "    pred_copy = copy.copy(pred)\n",
    "    for j in range(n):\n",
    "        i = np.argmax(pred_copy)\n",
    "        tops.append((i, \"%.2f\" % (pred_copy[i] * 100)))\n",
    "        pred_copy[i] = 0\n",
    "\n",
    "    return tops\n",
    "\n",
    "\n",
    "if args.infile:\n",
    "    preds = model.predict(x_test)\n",
    "    print(\"Prediction: top3:\", top_predictions(3, preds[0]))\n",
    "\n",
    "elif Pred_Details:\n",
    "    preds = model.predict(x_test)\t\n",
    "    for k, v in enumerate(preds):\n",
    "        p = np.argmax(v)\n",
    "        if p != test_label[k]:\n",
    "            print(\"Wrong prediction: top3:\", top_predictions(3, v),\n",
    "                  \"label/file:\", label_pngs[k][1], label_pngs[k][2])\n",
    "else:\n",
    "    loss, acc = model.evaluate(x_test, y_test, batch_size=64)\n",
    "    print(\"Loss:\", loss)\n",
    "    print(\"Accuracy:\", acc)\n",
    "\n",
    "backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "    One of our best models\n",
    "    This model achieves 97.2% top-1 accuracy on 2013 CASIA competition data,\n",
    "    better than any previously published results.\n",
    "\"\"\"\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "        Input,\n",
    "        Flatten,\n",
    "        Dense,\n",
    "        ZeroPadding2D,\n",
    "        Conv2D,\n",
    "        Activation,\n",
    "        MaxPooling2D,\n",
    "        BatchNormalization)\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "\n",
    "def relu():\n",
    "    return LeakyReLU(alpha=0.01)\n",
    "\n",
    "\n",
    "def conv_unit(input_tensor, nb_filters, mp=False, dropout=None):\n",
    "    \"\"\"\n",
    "    one conv-relu-bn unit\n",
    "    \"\"\"\n",
    "    x = ZeroPadding2D()(input_tensor)\n",
    "    x = Conv2D(nb_filters, (3, 3))(x)\n",
    "    x = relu()(x)\n",
    "    x = BatchNormalization(axis=3, momentum=0.66)(x)\n",
    "\n",
    "    if mp:\n",
    "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def out_block(input_tensor, nb_classes):\n",
    "    \"\"\"\n",
    "    FC output\n",
    "    \"\"\"\n",
    "    x = Flatten()(input_tensor)\n",
    "    x = Dense(1024)(x)\n",
    "    x = relu()(x)\n",
    "    x = BatchNormalization(momentum=0.66)(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = relu()(x)\n",
    "    x = BatchNormalization(momentum=0.66)(x)\n",
    "    x = Dense(nb_classes)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def model_8(img_size, num_classes):\n",
    "    \"\"\"\n",
    "    This is actually model N2B\n",
    "    5 blocks, 14 weight layers (1-2-2-3-3--3)\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(img_size, img_size, 1))\n",
    "    x = ZeroPadding2D()(inputs)\n",
    "    x = Conv2D(64, (3, 3), strides=(2, 2))(x)\n",
    "    x = relu()(x)\n",
    "    x = BatchNormalization(momentum=0.66)(x)\n",
    "    x = conv_unit(x, 128)\n",
    "    x = conv_unit(x, 128, mp=True)\n",
    "    x = conv_unit(x, 256)\n",
    "    x = conv_unit(x, 256, mp=True)\n",
    "    x = conv_unit(x, 384)\n",
    "    x = conv_unit(x, 384)\n",
    "    x = conv_unit(x, 384, mp=True)\n",
    "    x = conv_unit(x, 512)\n",
    "    x = conv_unit(x, 512)\n",
    "    x = conv_unit(x, 512, mp=True)\n",
    "    x = out_block(x, num_classes)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Activation at 0x1e588756860>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes_original = 3755\n",
    "WEIGHTS_PATH = os.path.join(\"anchor\",\"data\", \"weights08.h5\")\n",
    "\n",
    "\n",
    "\n",
    "model = model_8(IMG_SIZE, n_classes_original)\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.ZeroPadding2D at 0x1e5f5d886a0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers.add(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
